{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Severstal (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCVY8tqq6Pd5",
        "colab_type": "text"
      },
      "source": [
        "#UTILS.PY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJrHlhb6S8LH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "815f0373-ee5c-46ca-c8a0-052cc322c638"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Aug 26 08:14:19 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZdJn1QI5Jj-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "d5225483-0464-4bcd-ff84-ce50478e8d11"
      },
      "source": [
        "!pip install segmentation_models_pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting segmentation_models_pytorch\n",
            "  Using cached https://files.pythonhosted.org/packages/70/88/763a25dfe076a9f30f33466b1bd0f2d31b915b88d4cb4481fe4043cf26b4/segmentation_models_pytorch-0.1.0-py3-none-any.whl\n",
            "Processing /root/.cache/pip/wheels/e9/c6/e1/7a808b26406239712cfce4b5ceeb67d9513ae32aa4b31445c6/efficientnet_pytorch-0.7.0-cp36-none-any.whl\n",
            "Processing /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd/pretrainedmodels-0.7.4-cp36-none-any.whl\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from segmentation_models_pytorch) (0.7.0+cu101)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet-pytorch>=0.5.1->segmentation_models_pytorch) (1.6.0+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (4.41.1)\n",
            "Collecting munch\n",
            "  Using cached https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->segmentation_models_pytorch) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->segmentation_models_pytorch) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet-pytorch>=0.5.1->segmentation_models_pytorch) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.15.0)\n",
            "Installing collected packages: efficientnet-pytorch, munch, pretrainedmodels, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.0 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMxAIyRwzG5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def mask_to_rle(mask):\n",
        "    \"\"\"\n",
        "    mask:  numpy array,  1 - mask, 0 - background\n",
        "    return: run length as string formatted\n",
        "    \"\"\"\n",
        "    pixels = mask.T.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[:-1] != pixels[1:])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "\n",
        "def rle_to_mask(rle, shape=(1600, 256)):\n",
        "    \"\"\"\n",
        "    :param rle: run-length as string formated (start length)\n",
        "    :param shape: (width,height) of array to return\n",
        "    :return: numpy array, 1 - mask, 0 - background\n",
        "    \"\"\"\n",
        "    runs = np.array([int(x) for x in rle.split()])\n",
        "    runs[1::2] += runs[::2]\n",
        "    runs -= 1\n",
        "    starts, ends = runs[::2], runs[1::2]\n",
        "    mask = np.zeros(shape[0] * shape[1])\n",
        "    for start, end in zip(starts, ends):\n",
        "        mask[start:end] = 1\n",
        "    return mask.reshape(shape).T\n",
        "\n",
        "\n",
        "def show_defects(image, mask, pallet=((249, 192, 12), (0, 185, 241), (114, 0, 218), (249,50,12))):\n",
        "\n",
        "    for i in range(4):\n",
        "        image[0, mask[i] == 1] = 255\n",
        "    plt.imshow(image.permute(1, 2, 0))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def show_mask_image(image, mask, pallet=((249, 192, 12), (0, 185, 241), (114, 0, 218), (249, 50, 12))):\n",
        "    fig, ax = plt.subplots(figsize=(15, 15))\n",
        "    image = image.permute(1, 2, 0).numpy()\n",
        "    mask = mask.permute(1, 2, 0)\n",
        "\n",
        "    for ch in range(4):\n",
        "        image[mask[:, :, ch] == 1] = pallet[ch]\n",
        "    plt.imshow(image)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def make_mask(name, df):\n",
        "    mask = np.zeros((256, 1600, 4), dtype=np.float32)\n",
        "    rows = df.loc[name]\n",
        "    for defect in range(1, 5):\n",
        "        rle = rows[defect]\n",
        "        if not pd.isna(rle):\n",
        "            encoded = rle_to_mask(rle)\n",
        "            mask[:, :, defect - 1] = encoded\n",
        "    return mask\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "def dice_single_channel(targets, preds, eps=1e-9):\n",
        "    batch_size = preds.shape[0]\n",
        "    preds = preds.view((batch_size, -1)).float()\n",
        "    targets = targets.view((batch_size, -1)).float()\n",
        "    dice = (2 * (preds * targets).sum(1) + eps) / (preds.sum(1) + targets.sum(1) + eps)\n",
        "    return dice\n",
        "\n",
        "\n",
        "def mean_dice_score(targets, outputs, threshold=0.5):\n",
        "    batch_size = outputs.shape[0]\n",
        "    n_channels = outputs.shape[1]\n",
        "    preds = (outputs.sigmoid() > threshold).float()\n",
        "\n",
        "    mean_dice = 0\n",
        "    for i in range(n_channels):\n",
        "        dice = dice_single_channel(targets[:, i, :, :], preds[:, i, :, :])\n",
        "        mean_dice += dice.sum(0) / (n_channels * batch_size)\n",
        "    return mean_dice.item()\n",
        "\n",
        "\n",
        "def pixel_accuracy_score(targets, outputs, threshold=0.5):\n",
        "    preds = (outputs.sigmoid() > threshold).float()\n",
        "    correct = torch.sum((targets == preds)).item()\n",
        "    total = outputs.numel()\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "def epoch_metrics(targets, outputs, threshold=0.5):\n",
        "    return {'dice': mean_dice_score(targets, outputs, threshold),\n",
        "            'pixel_acc': pixel_accuracy_score(targets, outputs, threshold)}\n",
        "\n",
        "\n",
        "def predict(output, threshold=0.5):\n",
        "    prediction = (output.sigmoid() > threshold).float()\n",
        "    return prediction\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "import albumentations as albu\n",
        "import albumentations.pytorch as albu_pytorch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "class SteelDataset(Dataset):\n",
        "    def __init__(self, dataset, phase='train', data_dir='train_images', image_size=(256, 1600), n_classes=4):\n",
        "        self.dataset = dataset\n",
        "        self.phase = phase\n",
        "        self.dir = data_dir\n",
        "        self.transforms = get_transforms(phase=self.phase)\n",
        "        self.image_size = image_size\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        name = self.dataset.iloc[index].name\n",
        "        image = cv2.imread(os.path.join(self.dir, name))\n",
        "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        mask = make_mask(name, self.dataset)\n",
        "\n",
        "        transformed = self.transforms(image=image, mask=mask)\n",
        "        image, mask = transformed['image'], transformed['mask'][0].permute(2, 0 , 1)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "\n",
        "def get_transforms(list_transforms=None, phase='train'):\n",
        "    if not list_transforms:\n",
        "        list_transforms = []\n",
        "\n",
        "    if phase == 'train':\n",
        "        list_transforms.extend(\n",
        "            [\n",
        "                albu.RandomBrightnessContrast(p=0.1, brightness_limit=0.1, contrast_limit=0.1),\n",
        "                albu.HorizontalFlip(p=0.65),\n",
        "                albu.VerticalFlip(p=0.65),\n",
        "                # albu.ElasticTransform(p=0.5),\n",
        "                # albu.GridDistortion(p=0.5),\n",
        "                # albu.OpticalDistortion(p=0.5),\n",
        "            ]\n",
        "        )\n",
        "    list_transforms.extend(\n",
        "        [\n",
        "            albu.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "            albu_pytorch.ToTensor()\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    list_transforms = albu.Compose(list_transforms)\n",
        "    return list_transforms\n",
        "\n",
        "\n",
        "def data_provider(df, batch_size=8, shuffle=True, stratify_by=None):\n",
        "\n",
        "    if stratify_by:\n",
        "        train_df, val_df = train_test_split(df, test_size=0.2,\n",
        "                                            stratify=df[stratify_by],\n",
        "                                            random_state=42,\n",
        "                                            shuffle=shuffle)\n",
        "    else:\n",
        "        train_df, val_df = train_test_split(df, test_size=0.2,\n",
        "                                            random_state=42,\n",
        "                                            shuffle=shuffle)\n",
        "\n",
        "    dataloader = {'train': DataLoader(SteelDataset(train_df, phase='train'), batch_size=batch_size),\n",
        "                  'val': DataLoader(SteelDataset(val_df, phase='val'), batch_size=batch_size)}\n",
        "\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp8OsvEcaq4-",
        "colab_type": "text"
      },
      "source": [
        "# Radam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDb6IME2apUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim.optimizer import Optimizer\n",
        "import math\n",
        "class RAdam(Optimizer):\n",
        "\n",
        "    def __init__(self, params, lr=1e-5, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
        "        self.buffer = [[None, None, None] for ind in range(10)]\n",
        "        super(RAdam, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(RAdam, self).__setstate__(state)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data.float()\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
        "\n",
        "                p_data_fp32 = p.data.float()\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
        "                else:\n",
        "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "\n",
        "                state['step'] += 1\n",
        "                buffered = self.buffer[int(state['step'] % 10)]\n",
        "                if state['step'] == buffered[0]:\n",
        "                    N_sma, step_size = buffered[1], buffered[2]\n",
        "                else:\n",
        "                    buffered[0] = state['step']\n",
        "                    beta2_t = beta2 ** state['step']\n",
        "                    N_sma_max = 2 / (1 - beta2) - 1\n",
        "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
        "                    buffered[1] = N_sma\n",
        "\n",
        "                    # more conservative since it's an approximated value\n",
        "                    if N_sma >= 5:\n",
        "                        step_size = group['lr'] * math.sqrt(\n",
        "                            (1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (\n",
        "                                    N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
        "                    else:\n",
        "                        step_size = group['lr'] / (1 - beta1 ** state['step'])\n",
        "                    buffered[2] = step_size\n",
        "\n",
        "                if group['weight_decay'] != 0:\n",
        "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
        "\n",
        "                # more conservative since it's an approximated value\n",
        "                if N_sma >= 5:\n",
        "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                    p_data_fp32.addcdiv_(-1 * step_size, exp_avg, denom)\n",
        "                else:\n",
        "                    p_data_fp32.add_(-1 * step_size, exp_avg)\n",
        "\n",
        "                p.data.copy_(p_data_fp32)\n",
        "\n",
        "        return loss\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkOcGswr59cG",
        "colab_type": "text"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP9GIT0e6bmW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5dffc792-3ee1-4d10-bfca-0775b49beb32"
      },
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "files = ['/content/drive/My Drive/severstal/steel.zip', '/content/drive/My Drive/severstal/test_images.zip']\n",
        "for path_zip_file in files:\n",
        "    z = zipfile.ZipFile(path_zip_file, 'r')\n",
        "    z.extractall()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0w2hO3h8mSp",
        "colab_type": "text"
      },
      "source": [
        "# MODEL.PY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-I55xcWyLkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import segmentation_models_pytorch as smp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "DIR_TO_SAVE_MODELS = '/content/drive/My Drive/severstal/models'\n",
        "DIR_TO_SAVE_VALUES = '/content/drive/My Drive/severstal/values'\n",
        "DIR_TO_SAVE_LOG = '/content/drive/My Drive/severstal/log'\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, criterion, optimizer, scheduler, device, data_frame, batch_size=8, stratify_by=None):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.model = model.to(device)\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.device = device\n",
        "        self.batch_size = batch_size\n",
        "        self.accumulation_steps = 256 // self.batch_size\n",
        "        self.df = data_frame\n",
        "        self.dataloaders = data_provider(self.df, batch_size=self.batch_size, stratify_by=stratify_by)\n",
        "        self.losses = {phase: [] for phase in ['train', 'val']}\n",
        "        self.metrics = {'dice': mean_dice_score, 'pixel_acc': pixel_accuracy_score}\n",
        "        self.metrics_values = {phase: {name: [] for name in self.metrics.keys()}\n",
        "                               for phase in ['train', 'val']}\n",
        "        self.best_score = np.array([-np.inf for _ in self.metrics.keys()])\n",
        "\n",
        "    def step(self, epoch, phase):\n",
        "\n",
        "        epoch_loss = 0.0\n",
        "        metrics = {name: [] for name in self.metrics.keys()}\n",
        "        epoch_metric = {}\n",
        "\n",
        "        if phase == 'train':\n",
        "            self.model.train()\n",
        "        else:\n",
        "            self.model.eval()\n",
        "\n",
        "        dataloader = self.dataloaders[phase]\n",
        "        pbar = tqdm(dataloader, total=len(dataloader))\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        for i, (images, targets) in enumerate(dataloader):\n",
        "            images, targets = images.to(self.device), targets.to(self.device)\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = self.model(images)\n",
        "                loss = self.criterion(outputs, targets)\n",
        "\n",
        "                if phase == \"train\":\n",
        "                    loss.backward()\n",
        "                    if (i + 1) % self.accumulation_steps == 0:\n",
        "                        self.optimizer.step()\n",
        "                        self.optimizer.zero_grad()\n",
        "\n",
        "                for metric in self.metrics.keys():\n",
        "                    metrics[metric].append(self.metrics[metric](targets, outputs))\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "                pbar.update(1)\n",
        "                \n",
        "        pbar.close()\n",
        "        epoch_loss = (epoch_loss * self.accumulation_steps) / len(dataloader)\n",
        "        self.losses[phase].append(epoch_loss)\n",
        "\n",
        "        for metric in self.metrics.keys():\n",
        "            epoch_metric[metric] = np.mean(metrics[metric])\n",
        "            self.metrics_values[phase][metric].append(epoch_metric[metric])\n",
        "\n",
        "        del images, targets, outputs, loss\n",
        "        torch.cuda.empty_cache()\n",
        "        return epoch_loss, epoch_metric\n",
        "\n",
        "    def train(self, num_epochs):\n",
        "        for epoch in tqdm(range(num_epochs)):\n",
        "            loss, metric = self.step(epoch, 'train')\n",
        "            print('Epoch {} | train_loss {} | train_metric {}'.format(epoch, loss, metric))\n",
        "            state = {'epoch': epoch,\n",
        "                     'best_score': self.best_score,\n",
        "                     'state_dict': self.model.state_dict(),\n",
        "                     'optimizer': self.optimizer.state_dict()}\n",
        "\n",
        "            loss, metric = self.step(epoch, 'val')\n",
        "            print('Epoch {} | val_loss {} | val_metric {}'.format(epoch, loss, metric))\n",
        "            self.scheduler.step(loss)\n",
        "            scores = np.fromiter(metric.values(), dtype=np.float)\n",
        "            if (scores[0] > self.best_score[0]).all():\n",
        "                print('-' * 10 + 'New optimal model found and saved' + '-' * 10)\n",
        "                state['best_metric'] = metric\n",
        "                torch.save(state, \"{}/model_epoch_{}_score_{:.4f}.pth\".format(DIR_TO_SAVE_MODELS, epoch, scores[0]))\n",
        "     \n",
        "                losses_file = open(\"{}/losses/loss_epoch_{}.json\".format(DIR_TO_SAVE_VALUES, epoch), \"w\")\n",
        "                json.dump(self.losses, losses_file)\n",
        "                losses_file.close() \n",
        "\n",
        "                metrics_file = open(\"{}/metric/metric_epoch_{}.json\".format(DIR_TO_SAVE_VALUES, epoch), \"w\")\n",
        "                json.dump(self.metrics_values, metrics_file)\n",
        "                metrics_file.close() \n",
        "    \n",
        "                self.best_score = scores\n",
        "\n",
        "            losses_file = open(\"{}/losses/loss_epoch_{}.json\".format(DIR_TO_SAVE_LOG, epoch), \"w\")\n",
        "            json.dump(self.losses, losses_file)\n",
        "            losses_file.close() \n",
        "\n",
        "            metrics_file = open(\"{}/metric/metric_epoch_{}.json\".format(DIR_TO_SAVE_LOG, epoch), \"w\")\n",
        "            json.dump(self.metrics_values, metrics_file)\n",
        "            metrics_file.close()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3x1OgswCqeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class DiceBCELoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceBCELoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "        \n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        inputs = F.sigmoid(inputs)       \n",
        "        \n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        \n",
        "        intersection = (inputs * targets).sum()                            \n",
        "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
        "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
        "        Dice_BCE = 0.35 * BCE + 0.65 * dice_loss\n",
        "        \n",
        "        return Dice_BCE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B4-TTiC0r9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "if __name__ == '__main__':\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    model = smp.Unet('resnet34', encoder_weights=None, classes=4, activation=None)\n",
        "    state = torch.load('/content/drive/My Drive/severstal/models/model_epoch_23_score_0.8903.pth')\n",
        "    model.load_state_dict(state['state_dict'])\n",
        "    criterion = DiceBCELoss()\n",
        "    optimizer = RAdam(model.parameters(), lr=5e-4)\n",
        "    # optimizer = torch.optim.Adam(model.parameters(), lr=5e-6)\n",
        "    optimizer.load_state_dict(state['optimizer'])\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.9, mode=\"min\", patience=3, verbose=True)\n",
        "\n",
        "    df = pd.read_csv('/content/train.csv')\n",
        "    df = df.pivot(index='ImageId', columns='ClassId', values='EncodedPixels')\n",
        "    df['NumDefects'] = df.count(axis=1)\n",
        "\n",
        "    for state in optimizer.state.values():\n",
        "        for k, v in state.items():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                state[k] = v.cuda()\n",
        "\n",
        "    model_train = Trainer(\n",
        "        model=model,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        device=device,\n",
        "        batch_size=8,\n",
        "        data_frame=df,\n",
        "        stratify_by='NumDefects'\n",
        "    )\n",
        "\n",
        "model_train.best_score = [0.8903, -np.inf]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-bT0-aDDHXY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f05cf81e-b4fb-4de7-e764-de1cbc5f15ea"
      },
      "source": [
        "model_train.optimizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RAdam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    eps: 1e-08\n",
              "    lr: 0.00014348907\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBSnsR6AbJNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " for param_group in model_train.optimizer.param_groups:\n",
        "        param_group['lr'] = 3e-4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM0mWBHh2PvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/severstal/log/losses'\n",
        "file_list = os.listdir(path)\n",
        "full_list = [os.path.join(path, i) for i in file_list]\n",
        "time_sorted_list = sorted(full_list, key=os.path.getmtime, reverse=True)\n",
        "last_log = time_sorted_list[0]\n",
        "\n",
        "with open(os.path.join(path, last_log)) as json_file:\n",
        "    loss = json.load(json_file)\n",
        "\n",
        "model_train.losses['train'] = loss['train']\n",
        "model_train.losses['val'] = loss['val']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VD_-5Vb2IDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/severstal/log/metric'\n",
        "file_list = os.listdir(path)\n",
        "full_list = [os.path.join(path, i) for i in file_list]\n",
        "time_sorted_list = sorted(full_list, key=os.path.getmtime, reverse=True)\n",
        "last_log = time_sorted_list[0]\n",
        "\n",
        "with open(os.path.join(path, last_log)) as json_file:\n",
        "    metric = json.load(json_file)\n",
        "\n",
        "model_train.metrics_values['train']['dice'] = metric['train']['dice']\n",
        "model_train.metrics_values['val']['dice'] = metric['val']['dice']\n",
        "model_train.metrics_values['train']['pixel_acc'] = metric['train']['pixel_acc'] \n",
        "model_train.metrics_values['val']['pixel_acc']  = metric['val']['pixel_acc'] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "768XxYSk0r2e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "7acba1e0e17f4bac92a73a205b51662b",
            "ac5328d97845493e9efbdb88c15a99a1",
            "a2fcc7459c324727ad51c9d321065a3f",
            "23ceca1fec794738820f26264ad91986",
            "c42c8807314340a1b912110825789ee0",
            "3a9ae2e505fc4114b4176cc423af1f7b",
            "0d63eaed89754608b88a950866826a8e",
            "f320c408adb044bbaa128aaaf359eb66",
            "1cc6048087b44e37a815827cf41d3924",
            "6c6f2429c4f240f4a27a00e3f5565425",
            "f5c55594f94545c3803c81824ee7779d",
            "9f17054d79544d63971b97ff992df6b1",
            "40da532e7238419fa65e30f65d1bd5ea",
            "588cd1f758e0452c96f0644bc44b826d",
            "0f9f28baf8c84a859ecf1e69258a44be",
            "48d2ab66ece440b8900f4e84a67d9bef",
            "c6e2273716e14693af3083ab17d1502f",
            "e978730aee7e45319e2bbb3dd088fc8c",
            "6c4df315a8664142869bb932199a6f14",
            "0beed7adbe2e4b0fb8028fc15ea3342f",
            "6de2c593303648b68f73472b33b7465b",
            "f412fb9b824b46e8aaa65af96465e21e",
            "724ed7171a264fd2bc7b1d34889b19f3",
            "96916860dd4249489f797b5111cc9f57",
            "ad61636d0e65449caba5a5d33d5f49ff",
            "ce98949ab12e4055b2bfe66ff29767d7",
            "482b80fc040d4523887442ddd80d31d0"
          ]
        },
        "outputId": "2e7a9876-0aa7-4fdf-89db-6f9e1a684eb2"
      },
      "source": [
        "# torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "model_train.train(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:79: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7acba1e0e17f4bac92a73a205b51662b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac5328d97845493e9efbdb88c15a99a1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=667.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 0 | train_loss 1.8908817718054043 | train_metric {'dice': 0.952299028322257, 'pixel_acc': 0.9977469067666486}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2fcc7459c324727ad51c9d321065a3f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=167.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 0 | val_loss 5.677879433432025 | val_metric {'dice': 0.8898119944298338, 'pixel_acc': 0.9934844876287462}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23ceca1fec794738820f26264ad91986",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=667.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 | train_loss 1.874331474572286 | train_metric {'dice': 0.9510511839943847, 'pixel_acc': 0.997747171679358}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c42c8807314340a1b912110825789ee0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=167.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 | val_loss 5.6212962844414625 | val_metric {'dice': 0.8905528523250968, 'pixel_acc': 0.9934046969537488}\n",
            "Epoch    22: reducing learning rate of group 0 to 9.4143e-05.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a9ae2e505fc4114b4176cc423af1f7b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=667.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2 | train_loss 1.8592185808800865 | train_metric {'dice': 0.9518165896678793, 'pixel_acc': 0.9977708168544512}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d63eaed89754608b88a950866826a8e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=167.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2 | val_loss 5.645460477132283 | val_metric {'dice': 0.8913277694565094, 'pixel_acc': 0.9934177759593118}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f320c408adb044bbaa128aaaf359eb66",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=667.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3 | train_loss 1.8828165871628757 | train_metric {'dice': 0.9515412708093738, 'pixel_acc': 0.9977497511467655}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1cc6048087b44e37a815827cf41d3924",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=167.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3 | val_loss 5.687028792090045 | val_metric {'dice': 0.8904853166934259, 'pixel_acc': 0.9934318187660324}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c6f2429c4f240f4a27a00e3f5565425",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=667.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4 | train_loss 1.884440491939413 | train_metric {'dice': 0.9509121391369306, 'pixel_acc': 0.9977455673332157}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5c55594f94545c3803c81824ee7779d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=167.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4 | val_loss 5.673649445265353 | val_metric {'dice': 0.8893437974467249, 'pixel_acc': 0.9933523606778143}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f17054d79544d63971b97ff992df6b1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=667.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5 | train_loss 1.890939721550005 | train_metric {'dice': 0.9502291280826528, 'pixel_acc': 0.997732035052115}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40da532e7238419fa65e30f65d1bd5ea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=167.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5 | val_loss 5.762738633298588 | val_metric {'dice': 0.8878009333581982, 'pixel_acc': 0.993238324224354}\n",
            "Epoch    26: reducing learning rate of group 0 to 8.4729e-05.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "588cd1f758e0452c96f0644bc44b826d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=667.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6 | train_loss 1.8780497411737913 | train_metric {'dice': 0.9496014461345759, 'pixel_acc': 0.9977480196059197}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f9f28baf8c84a859ecf1e69258a44be",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=167.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6 | val_loss 5.752143567193768 | val_metric {'dice': 0.8891883317581908, 'pixel_acc': 0.9932654886759686}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48d2ab66ece440b8900f4e84a67d9bef",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=667.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7 | train_loss 1.9002314676409182 | train_metric {'dice': 0.9485703605761949, 'pixel_acc': 0.9977210275630007}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6e2273716e14693af3083ab17d1502f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=167.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7 | val_loss 5.649815052569269 | val_metric {'dice': 0.8907911049391695, 'pixel_acc': 0.9933131171129419}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e978730aee7e45319e2bbb3dd088fc8c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=667.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8 | train_loss 1.925387157493088 | train_metric {'dice': 0.9468906499456609, 'pixel_acc': 0.9976883940003266}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c4df315a8664142869bb932199a6f14",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=167.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8 | val_loss 5.601586290462288 | val_metric {'dice': 0.8915227062687903, 'pixel_acc': 0.9933742870399338}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0beed7adbe2e4b0fb8028fc15ea3342f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=667.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9 | train_loss 1.9416871193288148 | train_metric {'dice': 0.9477225793176505, 'pixel_acc': 0.9976627475675615}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6de2c593303648b68f73472b33b7465b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=167.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9 | val_loss 5.607789666352872 | val_metric {'dice': 0.891313717036904, 'pixel_acc': 0.9933619810245232}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f412fb9b824b46e8aaa65af96465e21e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=667.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10 | train_loss 1.9543788762821788 | train_metric {'dice': 0.9464657807993567, 'pixel_acc': 0.9976520094521222}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "724ed7171a264fd2bc7b1d34889b19f3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=167.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10 | val_loss 5.659140237077268 | val_metric {'dice': 0.8900469709299281, 'pixel_acc': 0.9932442101271093}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96916860dd4249489f797b5111cc9f57",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=667.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 11 | train_loss 1.944914953819458 | train_metric {'dice': 0.9452934154327484, 'pixel_acc': 0.9976644976385709}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad61636d0e65449caba5a5d33d5f49ff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=167.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 11 | val_loss 5.6237357248089275 | val_metric {'dice': 0.8895739666716067, 'pixel_acc': 0.993281868118012}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce98949ab12e4055b2bfe66ff29767d7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=667.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 12 | train_loss 1.9552524849392663 | train_metric {'dice': 0.9439882833560903, 'pixel_acc': 0.9976455734230052}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "482b80fc040d4523887442ddd80d31d0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=167.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZF47wWQe2y3",
        "colab_type": "text"
      },
      "source": [
        "# submitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtPNVjkgFTpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import os\n",
        "import cv2\n",
        "import segmentation_models_pytorch as smp\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "def test_generator(transforms, path_to_images='test_images'):\n",
        "    images_name = os.listdir(path_to_images)\n",
        "\n",
        "    for name in images_name:\n",
        "        image = cv2.imread(os.path.join(path_to_images, name))\n",
        "        image = transforms(image=image)['image']\n",
        "        yield image, name\n",
        "\n",
        "\n",
        "def make_submission(\n",
        "        model,\n",
        "        path_to_images='test_images',\n",
        "        device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')):\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    transforms = get_transforms(phase='val')\n",
        "    test_images = test_generator(transforms, path_to_images)\n",
        "    result = pd.DataFrame(columns=['ImageId', 'EncodedPixels', 'ClassId'])\n",
        "    pbar = tqdm(test_images, total=5506)\n",
        "    for image, name in test_images:\n",
        "        output = predict(model(image.unsqueeze(0).to(device)).cpu().detach())\n",
        "        for defect in range(4):\n",
        "            rle = mask_to_rle(output[:, defect, :, :])\n",
        "            result = result.append({'ImageId': name, 'EncodedPixels': rle, 'ClassId': defect + 1}, ignore_index=True)\n",
        "        pbar.update(1)\n",
        "    pbar.close()\n",
        "    return result\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    model = smp.Unet('resnet18', classes=4, activation=None)\n",
        "    model.load_state_dict(torch.load('/content/drive/My Drive/models/model_epoch_19_score_0.8847.pth', map_location=device)['state_dict'])\n",
        "    result = make_submission(model, path_to_images='/content/test_images')\n",
        "    result.to_csv(\"submission.csv\", index=False)\n",
        "    print(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}